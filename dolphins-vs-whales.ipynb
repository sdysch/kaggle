{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-09T20:44:33.870002Z","iopub.execute_input":"2022-02-09T20:44:33.87031Z","iopub.status.idle":"2022-02-09T20:44:34.115861Z","shell.execute_reply.started":"2022-02-09T20:44:33.870227Z","shell.execute_reply":"2022-02-09T20:44:34.115111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/happy-whale-and-dolphin/train.csv\")\nprint(df_train.head())","metadata":{"execution":{"iopub.status.busy":"2022-02-09T20:44:34.117574Z","iopub.execute_input":"2022-02-09T20:44:34.117844Z","iopub.status.idle":"2022-02-09T20:44:34.209214Z","shell.execute_reply.started":"2022-02-09T20:44:34.117808Z","shell.execute_reply":"2022-02-09T20:44:34.208498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def list_full_paths(directory):\n    return [os.path.join(directory, file) for file in os.listdir(directory)]\n\nimage_path = '../input/happy-whale-and-dolphin/train_images/'\ndf_train['filepath'] = list_full_paths(image_path)\nprint(df_train.head())","metadata":{"execution":{"iopub.status.busy":"2022-02-09T20:44:34.210294Z","iopub.execute_input":"2022-02-09T20:44:34.210694Z","iopub.status.idle":"2022-02-09T20:44:35.108899Z","shell.execute_reply.started":"2022-02-09T20:44:34.210657Z","shell.execute_reply":"2022-02-09T20:44:35.108169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot a few example images\nfig, ax = plt.subplots(2, 2, figsize=(10, 10))\nfor a in ax.ravel():\n    a.axis('off')\nax[0, 0].imshow(cv2.imread(df_train['filepath'].iloc[0]))\nax[0, 1].imshow(cv2.imread(df_train['filepath'].iloc[1]))\nax[1, 0].imshow(cv2.imread(df_train['filepath'].iloc[2]))\nax[1, 1].imshow(cv2.imread(df_train['filepath'].iloc[3]))","metadata":{"execution":{"iopub.status.busy":"2022-02-09T20:44:35.109985Z","iopub.execute_input":"2022-02-09T20:44:35.110755Z","iopub.status.idle":"2022-02-09T20:44:38.871425Z","shell.execute_reply.started":"2022-02-09T20:44:35.110718Z","shell.execute_reply":"2022-02-09T20:44:38.870725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cleanup species labels\n#print(df_train['species'].unique())\ndf_train['species'].replace({\n    'beluga'            : 'beluga_whale',\n    'globis'            : 'short_finned_pilot_whale',\n    'pilot_whale'       : 'short_finned_pilot_whale',\n    'bottlenose_dolpin' : 'bottlenose_dolphin',\n    'kiler_whale'       : 'killer_whale',\n}, inplace=True)\nprint(df_train['species'].unique())\nprint(f'{len(df_train[\"species\"].unique())} unique values')","metadata":{"execution":{"iopub.status.busy":"2022-02-09T20:44:38.873271Z","iopub.execute_input":"2022-02-09T20:44:38.87422Z","iopub.status.idle":"2022-02-09T20:44:38.909485Z","shell.execute_reply.started":"2022-02-09T20:44:38.87418Z","shell.execute_reply":"2022-02-09T20:44:38.90881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of each category\ndf_train['species'].value_counts().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2022-02-09T20:44:38.910741Z","iopub.execute_input":"2022-02-09T20:44:38.911441Z","iopub.status.idle":"2022-02-09T20:44:39.271185Z","shell.execute_reply.started":"2022-02-09T20:44:38.911406Z","shell.execute_reply":"2022-02-09T20:44:39.270507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_train = np_utils.to_categorical(df_train['species'])\n#print(y_train)\n\ncategories = df_train['species'].unique()\nn_unique = len(categories)\n\n# OneHotEncode\n#from keras.utils import np_utils\n#encoder = { category: label for category, label in zip( categories, range(n_unique) ) }\n#df_train['species'] = df_train['species'].apply(lambda x: encoder[x])\n#print(df_train.head())\n\nprint(categories)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T20:44:39.27251Z","iopub.execute_input":"2022-02-09T20:44:39.272769Z","iopub.status.idle":"2022-02-09T20:44:39.282383Z","shell.execute_reply.started":"2022-02-09T20:44:39.272733Z","shell.execute_reply":"2022-02-09T20:44:39.281571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n# load images into data generator\n\n# split train into train and validation, ensuring reproducability\nfrom sklearn.model_selection import train_test_split\ntrain, validation = train_test_split(df_train, test_size=0.2, random_state=42, shuffle=True)\n\ntrain_gen = ImageDataGenerator(rescale=1. / 255)\ntrain_generator = train_gen.flow_from_dataframe(dataframe=train, x_col='filepath', y_col='species', class_mode='categorical')\n\nval_gen = ImageDataGenerator(rescale=1. / 255)\nval_generator = val_gen.flow_from_dataframe(dataframe=validation, x_col='filepath', y_col='species', class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2022-02-09T20:44:39.284089Z","iopub.execute_input":"2022-02-09T20:44:39.284695Z","iopub.status.idle":"2022-02-09T20:45:39.678067Z","shell.execute_reply.started":"2022-02-09T20:44:39.284658Z","shell.execute_reply":"2022-02-09T20:45:39.677314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Number of species in train/validation","metadata":{}},{"cell_type":"code","source":"train['species'].value_counts().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2022-02-09T20:45:39.679384Z","iopub.execute_input":"2022-02-09T20:45:39.679791Z","iopub.status.idle":"2022-02-09T20:45:40.028316Z","shell.execute_reply.started":"2022-02-09T20:45:39.679753Z","shell.execute_reply":"2022-02-09T20:45:40.027615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation['species'].value_counts().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2022-02-09T20:45:40.029579Z","iopub.execute_input":"2022-02-09T20:45:40.029995Z","iopub.status.idle":"2022-02-09T20:45:40.385283Z","shell.execute_reply.started":"2022-02-09T20:45:40.029957Z","shell.execute_reply":"2022-02-09T20:45:40.384524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple CNN for initial test, and trial some basic data augmentation","metadata":{}},{"cell_type":"code","source":"# data augmentation\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n\ninput_shape = (255, 255, 3)\n\n#data_augmentation = keras.Sequential()\n#data_augmentation.add(RandomFlip('horizontal', input_shape=input_shape))\n#data_augmentation.add(RandomRotation(0.1))\n#data_augmentation.add(RandomZoom(0.1))\n\n# model definition\nmodel = Sequential()\n\n#model.add(data_augmentation)\n\nmodel.add(Conv2D(input_shape=input_shape, filters=32, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(input_shape=input_shape, filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(input_shape=input_shape, filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(2, 2))\n\n\nmodel.add(Flatten())\n\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(n_unique, activation='softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T20:45:40.386672Z","iopub.execute_input":"2022-02-09T20:45:40.386921Z","iopub.status.idle":"2022-02-09T20:45:42.80306Z","shell.execute_reply.started":"2022-02-09T20:45:40.386886Z","shell.execute_reply":"2022-02-09T20:45:42.802323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking GPU is on\n!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-02-09T20:45:42.804575Z","iopub.execute_input":"2022-02-09T20:45:42.805105Z","iopub.status.idle":"2022-02-09T20:45:43.517417Z","shell.execute_reply.started":"2022-02-09T20:45:42.805069Z","shell.execute_reply":"2022-02-09T20:45:43.516585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit data\nfrom tensorflow.keras.optimizers import Adam\noptimizer = Adam()\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# callbacks\nes = EarlyStopping(monitor='val_loss', patience=15, verbose=1, mode='min', restore_best_weights=True)\n#lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min', min_lr=0.00000001)\ncallbacks = [es]\n\n#epochs = 20\nepochs = 1\nwith tf.device('/device:GPU:0'):\n    history = model.fit(train_generator,\n                        validation_data=val_generator,\n                        epochs=epochs,\n                        callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T21:46:00.193698Z","iopub.execute_input":"2022-02-09T21:46:00.194266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize = (10, 5))\n_ = axs[0].plot(history.history['loss'], label='Test')\n_ = axs[0].plot(history.history['val_loss'], label='Validation')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('loss')\n_ = axs[0].legend()\n\n_ = axs[1].plot(history.history['accuracy'], label='Test')\n_ = axs[1].plot(history.history['val_accuracy'], label='Validation')\naxs[1].set_xlabel('epochs')\naxs[1].set_ylabel('accuracy')\n_ = axs[1].legend()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T21:36:17.981205Z","iopub.execute_input":"2022-02-09T21:36:17.981419Z","iopub.status.idle":"2022-02-09T21:36:18.570433Z","shell.execute_reply.started":"2022-02-09T21:36:17.98139Z","shell.execute_reply":"2022-02-09T21:36:18.569428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ETA for 1 epoch is 1hr....","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}